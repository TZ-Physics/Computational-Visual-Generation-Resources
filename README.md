# Computational-Visual-Generation-Resources

## Review

**Artifcial intelligence in the creative industries: a review.**<br>
*N Anantrasirichai, D Bull.*<br>
Artifcial Intelligence Review, 2021. 

**A complete survey on generative ai (aigc): Is chatgpt from gpt-4 to gpt-5 all you need?.**<br>
*C Zhang, C Zhang, S Zheng, Y Qiao, C Li, et al.*<br>
arXiv, 2023. 

**State of the art on diffusion models for visual computing.**<br>
*R Po, W Yifan, V Golyanik, K Aberman, JT Barron, AH Bermano, ER Chan, T Dekel, et al.*<br>
arXiv:2310.07204, 2023. 
[[Paper](https://arxiv.org/pdf/2310.07204)]

## Image Generation

### Layout

**Image Generation from Layout.**<br>
*B Zhao, L Meng, W Yin, L Sigal.*<br>
CVPR, 2019. 
[[Paper](https://arxiv.org/pdf/2104.11487.pdf)]
[[Github](https://github.com/zhaobozb/layout2im)]

**Layout2image Image Generation from Layout.**<br>
*B Zhao, W Yin, L Meng, L Sigal.*<br>
IJCV, 2020.

**Posterlayout: A new benchmark and approach for content-aware visual-textual presentation layout.**<br>
*HY Hsu, X He, Y Peng, H Kong, Q Zhang.*<br>
CVPR, 2023.
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Hsu_PosterLayout_A_New_Benchmark_and_Approach_for_Content-Aware_Visual-Textual_Presentation_CVPR_2023_paper.pdf)]
[[Github](https://github.com/PKU-ICST-MIPL/PosterLayout-CVPR2023)]

### Composition

**Making images real again: A comprehensive survey on deep image composition.**<br>
*L Niu, W Cong, L Liu, Y Hong, B Zhang, J Liang, et al.*<br>
arXiv, 2021.
[[Paper](https://arxiv.org/pdf/2106.14490)]

**Shadow generation for composite image in real-world scenes.**<br>
*Y Hong, L Niu, J Zhang.*<br>
AAAI, 2022.
[[Paper](https://ojs.aaai.org/index.php/AAAI/article/download/19974/19733)]

**Current advances and future perspectives of image fusion: A comprehensive review.**<br>
*S Karim, G Tong, J Li, A Qadir, U Farooq, Y Yu.*<br>
Information Fusion, 2023.
[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S1566253522001518)]

### Editing

**In-domain gan inversion for real image editing.**<br>
*J Zhu, Y Shen, D Zhao, B Zhou.*<br>
ECCV, 2020.

**Anycost gans for interactive image synthesis and editing.**<br>
*J Lin, R Zhang, F Ganz, S Han, et al.*<br>
CVPR, 2021.

**EditGAN: High-Precision Semantic Image Editing.**<br>
*H Ling, K Kreis, D Li, SW Kim, et al.*<br>
NIPS, 2021.

### Controllable

**Condition-Aware Neural Network for Controlled Image Generation.**<br>
*H Cai, M Li, Q Zhang, MY Liu, S Han.*<br>
CVPR, 2024.

**DialogGen: Multi-modal Interactive Dialogue System for Multi-turn Text-to-Image Generation.**<br>
*M Huang, Y Long, X Deng, R Chu, J Xiong, X Liang, H Cheng, Q Lu, W Liu.*<br>
arXiv:2403.08857, 2024.
[[Paper](https://arxiv.org/pdf/2403.08857)]
[[Github](https://hunyuan-dialoggen.github.io/)]

**Prompt Highlighter: Interactive Control for Multi-Modal LLMs.**<br>
*Y Zhang, S Qian, B Peng, S Liu, J Jia.*<br>
CVPR, 2024.
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Prompt_Highlighter_Interactive_Control_for_Multi-Modal_LLMs_CVPR_2024_paper.pdf)]
[[Github](https://github.com/dvlab-research/Prompt-Highlighter)]

### Diffusion

**High-resolution image synthesis with latent diffusion models.**<br>
*R Rombach, A Blattmann, D Lorenz, et al.*<br>
CVPR, 2022.
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)]

**Layoutdiffusion: Controllable diffusion model for layout-to-image generation.**<br>
*G Zheng, X Zhou, X Li, Z Qi, et al.*<br>
CVPR, 2023.
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_LayoutDiffusion_Controllable_Diffusion_Model_for_Layout-to-Image_Generation_CVPR_2023_paper.pdf)]

**InteractDiffusion: Interaction Control in Text-to-Image Diffusion Models.**<br>
*JT Hoe, X Jiang, CS Chan, et al.*<br>
CVPR, 2024.
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Hoe_InteractDiffusion_Interaction_Control_in_Text-to-Image_Diffusion_Models_CVPR_2024_paper.pdf)]
[[Github](https://jiuntian.github.io/interactdiffusion/)]

### Applications

**Intelligent design of multimedia content in Alibaba.**<br>
*K. Liu, and et al.*<br>
Front Inform Technol Electron Eng, 2019, 20(12):1657-1664.
[[Paper](https://arxiv.org/pdf/2104.11487.pdf)]
[[Github](https://github.com/zhaobozb/layout2im)]

**Content-aware generative modeling of graphic design layouts.**<br>
*X Zheng, X Qiao, Y Cao, RWH Lau.*<br>
TOG, 2019.

**Automatic synthesis of advertising images according to a specified style.**<br>
*W. You, and et al.*<br>
Front Inform Technol Electron Eng, 2020.
[[Paper](https://arxiv.org/pdf/2104.11487.pdf)]
[[Github](https://github.com/zhaobozb/layout2im)]

**Enabling hyper-personalisation: Automated ad creative generation and ranking for fashion e-commerce.**<br>
*S Vempati, KT Malayil, V Sruthi, R Sandeep.*<br>
FRS, 2020.

**N\" uwa: Visual synthesis pre-training for neural visual world creation.**<br>
*C Wu, J Liang, L Ji, F Yang, Y Fang, D Jiang, et al.*<br>
ArXiv, 2021. 

**Vinci: An Intelligent Graphic Design System for Generating Advertising Posters.**<br>
*S Guo, Z Jin, F Sun, J Li, Z Li, Y Shi, N Cao.*<br>
CHI, 2021.

**Preparing for an era of deepfakes and AI-generated ads: A framework for understanding responses to manipulated advertising.**<br>
*C Campbell, K Plangger, S Sands, et al.*<br>
Journal of Advertisment, 2021.

### Image Manipulation Detection

**Learning Rich Features for Image Manipulation Detection.**<br>
*P Zhou, X Han, VI Morariu, et al.*<br>
CVPR, 2018. 
[[Paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Learning_Rich_Features_CVPR_2018_paper.pdf)]

**Faceforensics++: Learning to detect manipulated facial images.**<br>
*A Rossler, D Cozzolino, L Verdoliva, et al.*<br>
CVPR, 2019.

**Constrained R-CNN A general image manipulation detection model.**<br>
*C Yang, H Li, F Lin, B Jiang, et al.*<br>
ICME, 2020. 
[[Paper](https://arxiv.org/pdf/1911.08217.pdf)]

**Media Forensics and DeepFakes.**<br>
*L Verdoliva.*<br>
IEEE Journal of Selected Topics in Signal Processing, 2020. 
[[Paper](https://arxiv.org/pdf/2001.06564.pdf)]

**The creation and detection of deepfakes: A survey.**<br>
*Y Mirsky, W Lee.*<br>
ACM Computing Surveys (CSUR), 2021.

**Multi-Modality Image Manipulation Detection.**<br>
*C Yang, Z Wang, H Shen, H Li, et al.*<br>
ICME, 2021. 
[[Paper](https://ieeexplore.ieee.org/abstract/document/9428232)]

**Adversarial deepfakes: Evaluating vulnerability of deepfake detectors to adversarial examples.**<br>
*S Hussain, P Neekhara, M Jere, et al.*<br>
WACV, 2021. 
[[Paper](https://openaccess.thecvf.com/content/WACV2021/papers/Hussain_Adversarial_Deepfakes_Evaluating_Vulnerability_of_Deepfake_Detectors_to_Adversarial_Examples_WACV_2021_paper.pdf)]

**Exploiting deep generative prior for versatile image restoration and manipulation.**<br>
*X Pan, X Zhan, B Dai, D Lin, CC Loy, et al.*<br>
TPAMI, 2021.

**Online handwritten signature verification using feature weighting algorithm relief.**<br>
*L Yang, Y Cheng, X Wang, Q Liu.*<br>
Soft Computing, 2018. 
[[Paper](https://link.springer.com/article/10.1007/s00500-018-3477-2)]

**Characterizing and evaluating adversarial examples for Offline Handwritten Signature Verification.**<br>
*LG Hafemann, R Sabourin, et al.*<br>
IEEE Transactions on Information Forensics and Security, 2020. 
[[Paper](https://arxiv.org/pdf/1901.03398.pdf)]

**TextStyleBrush: Transfer of Text Aesthetics from a Single Example.**<br>
*P Krishnan, R Kovvuri, G Pang, B Vassilev, et al.*<br>
ArXiv, 2021. 
[[Paper](https://arxiv.org/pdf/2106.08385)]

## Video Generation

**Video to Video Synthesis.**<br>
*TC Wang, MY Liu, JY Zhu, G Liu, A Tao, J Kautz, et al.*<br>
NIPS, 2018.

**Mocogan: Decomposing motion and content for video generation.**<br>
*S Tulyakov, MY Liu, X Yang, et al.*<br>
CVPR, 2018.

**Playable Video Generation.**<br>
*W Menapace, S Lathuilière, et al.*<br>
CVPR, 2021.
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Menapace_Playable_Video_Generation_CVPR_2021_paper.pdf)]

**A good image generator is what you need for high-resolution video synthesis.**<br>
*Y Tian, J Ren, M Chai, K Olszewski, X Peng, et al.*<br>
ICLR, 2021.
[[Paper](https://arxiv.org/pdf/2104.15069.pdf)]

**From Sora What We Can See: A Survey of Text-to-Video Generation.**<br>
*R Sun, Y Zhang, T Shah, J Sun, S Zhang, W Li, H Duan, B Wei, R Ranjan.*<br>
arXiv:2405.10674, 2024.
[[Paper](https://arxiv.org/pdf/2405.10674)]

**Sora as an agi world model? a complete survey on text-to-video generation.**<br>
*J Cho, FD Puspitasari, S Zheng, J Zheng, LH Lee, TH Kim, CS Hong, C Zhang.*<br>
arXiv:2403.05131, 2024.
[[Paper](https://arxiv.org/pdf/2403.05131)]

**InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions.**<br>
*Y Zhang, Y Kang, Z Zhang, X Ding, S Zhao, X Yue.*<br>
arXiv:2402.03040, 2024.
[[Paper](https://arxiv.org/pdf/2402.03040)]
[[Github](https://invictus717.github.io/InteractiveVideo/)]

**Direct-a-video: Customized video generation with user-directed camera movement and object motion.**<br>
*S Yang, L Hou, H Huang, C Ma, P Wan, D Zhang, X Chen, J Liao.*<br>
SIGGRAPH, 2024.

**Cameractrl: Enabling camera control for text-to-video generation.**<br>
*H He, Y Xu, Y Guo, G Wetzstein, B Dai, H Li, C Yang.*<br>
arXiv:2404.02101, 2024.
[[Paper](https://arxiv.org/pdf/2404.02101)]

**Training-free Camera Control for Video Generation.**<br>
*C Hou, G Wei, Y Zeng, Z Chen.*<br>
arXiv:2406.10126, 2024.
[[Paper](https://arxiv.org/pdf/2406.10126)]

### Video Manipulation Detection

**Deepfake Video Detection Using Recurrent Neural Networks.**<br>
*D Güera, EJ Delp.*<br>
AVSS, 2018. 
[[Paper](https://gangw.cs.illinois.edu/class/cs598/papers/AVSS18-deepfake.pdf)]

**Faceforensics: A large-scale video dataset for forgery detection in human faces.**<br>
*A Rössler, D Cozzolino, L Verdoliva, C Riess, et al.*<br>
ArXiv, 2018. 
[[Paper](https://arxiv.org/pdf/1803.09179v1.pdf)]

**Mesonet: a compact facial video forgery detection network.**<br>
*D Afchar, V Nozick, J Yamagishi, et al.*<br>
WIFS, 2018. 
[[Paper](https://igm.univ-mlv.fr/~vnozick/publications/afchar_WIFS_2018/afchar_WIFS_2018.pdf)]

**Face Forensics in the Wild.**<br>
*T Zhou, W Wang, Z Liang, et al.*<br>
CVPR, 2021.

## Audio Generation

**Wavenet: A generative model for raw audio.**<br>
*A Oord, S Dieleman, H Zen, K Simonyan, et al.*<br>
ArXiv, 2016.

**Applications of Deep Learning to Audio Generation.**<br>
*Y Zhao, X Xia, R Togneri.*<br>
ICSM, 2018.

**Gansynth: Adversarial neural audio synthesis.**<br>
*J Engel, KK Agrawal, S Chen, I Gulrajani, et al.*<br>
ICLR, 2019.

**magenta**<br>
*Magenta is a research project exploring the role of machine learning in the process of creating art and music.*<br>
[[Github](https://github.com/magenta/magenta)]

### Audio Manipulation

**All your voices are belong to us: Stealing voices to fool humans and machines.**<br>
*D Mukhopadhyay, M Shirvanian, N Saxena.*<br>
ESORICS, 2015. 
[[Paper](https://cpb-us-w2.wpmucdn.com/sites.uab.edu/dist/f/65/files/2019/12/mss-esorics15.pdf)]

**Deepsonar: Towards effective and robust detection of ai-synthesized fake voices.**<br>
*R Wang, F Juefei-Xu, Y Huang, Q Guo, X Xie, et al.*<br>
MM, 2018. 
[[Paper](https://arxiv.org/pdf/2005.13770.pdf)]

**ASVspoof 2019: Future horizons in spoofed and fake audio detection.**<br>
*M Todisco, X Wang, V Vestman, M Sahidullah, et al.*<br>
ArXiv, 2019. 
[[Paper](https://arxiv.org/pdf/1904.05441)]

**Deep4SNet: deep learning for fake speech classification.**<br>
*DM Ballesteros, Y Rodriguez-Ortega, D Renza, et al.*<br>
ESWA, 2021. 
[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0957417421008770)]

## Illumination

**Deep neural models for illumination estimation and relighting: A survey.**<br>
*F Einabadi, JY Guillemaut, A Hilton.*<br>
Computer Graphics Forum, 2021.

**Lightit: Illumination modeling and control for diffusion models.**<br>
*P Kocsis, J Philip, K Sunkavalli, M Nießner, Y Hold-Geoffroy.*<br>
CVPR, 2024.
[[CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Kocsis_LightIt_Illumination_Modeling_and_Control_for_Diffusion_Models_CVPR_2024_paper.pdf)]

**Retinex-Diffusion: On Controlling Illumination Conditions in Diffusion Models via Retinex Theory.**<br>
*X Xing, VT Hu, JH Metzen, K Groh, S Karaoglu, T Gevers.*<br>
arXiv:2407.20785, 2024.
[[ArXiv](https://arxiv.org/pdf/2407.20785)]

## Reconstruction

**KinectFusion: real-time 3D reconstruction and interaction using a moving depth camera.**<br>
*S Izadi, D Kim, O Hilliges, D Molyneaux, et al.*<br>
UIST, 2011.

**Soft 3D reconstruction for view synthesis.**<br>
*E Penner, L Zhang.*<br>
ACM Transactions on Graphics (TOG), 2017.

**State of the Art on 3D Reconstruction with RGB‐D Cameras.**<br>
*M Zollhöfer, P Stotko, A Görlitz, et al.*<br>
Computer Graphics Forum, 2018.

**Disn: Deep implicit surface network for high-quality single-view 3d reconstruction.**<br>
*Q Xu, W Wang, D Ceylan, R Mech, et al.*<br>
NIPS, 2019.

**Occupancy networks: Learning 3d reconstruction in function space.**<br>
*L Mescheder, M Oechsle, M Niemeyer, et al.*<br>
CVPR, 2019.

**Fast Online 3D Reconstruction of Dynamic Scenes From Individual Single-Photon Detection Events.**<br>
*Y Altmann, S McLaughlin, et al.*<br>
IEEE Transactions on Signal Processing, 2019.

**DI-Fusion: Online Implicit 3D Reconstruction with Deep Priors.**<br>
*J Huang, SS Huang, H Song, et al.*<br>
CVPR, 2021.

**SP-GAN: Sphere-guided 3D shape generation and manipulation.**<br>
*R Li, X Li, KH Hui, CW Fu.*<br>
ACM Transactions on Graphics (TOG), 2021.

## Neural Rendering

**Neural scene representation and rendering.**<br>
*SMA Eslami, DJ Rezende, F Besse, F Viola, et al.*<br>
Science, 2018.
[[Github](https://github.com/deepmind/gqn-datasets)]

**Deferred neural rendering: Image synthesis using neural textures.**<br>
*J Thies, M Zollhöfer, M Nießner.*<br>
ACM Transactions on Graphics (TOG), 2019.

**NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis.**<br>
*B Mildenhall, PP Srinivasan, M Tancik, JT Barron, R Ramamoorthi, R Ng.*<br>
ECCV 2020. 
[[Paper](https://arxiv.org/abs/2003.08934)] [[Project](http://tancik.com/nerf)]

**SIREN: Implicit Neural Representations with Periodic Activation Functions.**<br>
*V Sitzmann, JNP Martel, AW Bergman, DB Lindell, et al.*<br>
NeurIPS 2020 (Oral). 
[[Paper](https://arxiv.org/abs/2006.09661)][[Github](http://vsitzmann.github.io/siren/)]

**Neural Ray-Tracing: Learning Surfaces and Reflectance for Relighting and View Synthesis.**<br>
*J Knodt, SH Baek, F Heide.*<br>
ArXiv, 2021.
[[Github](https://github.com/princeton-computational-imaging/neural_raytracing)]

**Autoint: Automatic integration for fast neural volume rendering.**<br>
*DB Lindell, JNP Martel, et al.*<br>
CVPR, 2021.
[[Github](https://github.com/princeton-computational-imaging/neural-scene-graphs)]

**NeRF in the Wild Neural Radiance Fields for Unconstrained Photo Collections.**<br>
*R Martin-Brualla, N Radwan, et al.*<br>
CVPR, 2021.

**Neural scene graphs for dynamic scenes.**<br>
*J Ost, F Mannan, N Thuerey, et al.*<br>
CVPR, 2021.
[[Github](https://github.com/princeton-computational-imaging/neural-scene-graphs)]

**ACORN: Adaptive Coordinate Networks for Neural Scene Representation.**<br>
*JJNP Martel, DB Lindell, CZ Lin, ER Chan, et al.*<br>
SIGGRAPH, 2021.
[[Github](https://github.com/computational-imaging/ACORN)]

**awesome neural rendering.**<br>
*Deep image or video generation approaches that enable explicit or implicit control of scene properties such as illumination, camera parameters, pose, geometry, appearance, and semantic structure..*<br>
[[Github](https://github.com/weihaox/awesome-neural-rendering)]

## Scene Generation

**Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion.**<br>
*B Deng, R Tucker, Z Li, L Guibas, N Snavely, G Wetzstein.*<br>
SIGGRAPH, 2024.

**MegaScenes: Scene-Level View Synthesis at Scale.**<br>
*J Tung, G Chou, R Cai, G Yang, K Zhang, G Wetzstein, B Hariharan, et al.*<br>
ECCV, 2024.

**Street-view image generation from a bird's-eye view layout.**<br>
*A Swerdlow, R Xu, B Zhou.*<br>
IEEE Robotics and Automation Letters, 2024.

**UrbanWorld: An Urban World Model for 3D City Generation.**<br>
*Yu Shang, Jiansheng Chen, Hangyu Fan, Jingtao Ding, Jie Feng, Yong Li.*<br>
ArXiv, 2024.
[[ArXiv](https://arxiv.org/pdf/2407.11965)]

## Immersive-Experiences

### Vision Scene

**Gaudi: A neural architect for immersive 3d scene generation.**<br>
*MA Bautista, P Guo, S Abnar, et al.*<br>
NeurIPS, 2022.

**Text2immersion: Generative immersive scene with 3d gaussians.**<br>
*H Ouyang, K Heal, S Lombardi, T Sun.*<br>
arxiv:2312.09242, 2023.

**DreamScene: 3D Gaussian-based Text-to-3D Scene Generation via Formation Pattern Sampling.**<br>
*H Li, H Shi, W Zhang, W Wu, Y Liao, L Wang, et al.*<br>
ArXiv, 2024. 

**Prompt Engineering, Tools and Methods for Immersive Experience Development.**<br>
*A Rozo-Torres, WJ Sarmiento.*<br>
IEEE VR, 2024.

### Audio Scene

**Speak in the Scene: Diffusion-based Acoustic Scene Transfer toward Immersive Speech Generation.**<br>
*M Kim, SW Chung, Y Ji, HG Kang, MS Choi.*<br>
arxiv:2406.12688, 2024.

### ASMR

**Neural Moderation of ASMR Erotica Content in Social Networks.**<br>
*Y Chen, D Jiang, C Tan, Y Song, C Zhang, L Chen.*<br>
IEEE Transactions on Knowledge and Data Engineering, 2023.
